{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "e68cb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "69fcab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "272eab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c5913c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "63aafa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Ansh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "11c5e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f35f6ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7904\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7904/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(message, history):\n",
    "    parts = [{\"text\": system_prompt}]\n",
    "    for user, bot in history:\n",
    "        parts.append({\"text\": user})\n",
    "        parts.append({\"text\": bot})\n",
    "    parts.append({\"text\": message})\n",
    "\n",
    "    response = model.generate_content(parts)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "gr.ChatInterface(chatbot, type=\"tuples\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ceb21b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ef2e936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"\"\"You are an evaluator that decides whether a response to a question is acceptable.\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is of acceptable quality.\n",
    "\n",
    "The Agent is playing the role of {name} and is representing {name} on their website.\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website.\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details.\n",
    "\n",
    "Here is the context:\n",
    "## Summary:\n",
    "{summary}\n",
    "\n",
    "## LinkedIn Profile:\n",
    "{linkedin}\n",
    "\n",
    "---\n",
    "\n",
    "You must reply with a JSON object only, in the following format:\n",
    "\n",
    "{{\n",
    "  \"is_acceptable\": true,\n",
    "  \"feedback\": \"Your feedback here.\"\n",
    "}}\n",
    "\n",
    "⚠️ Do NOT include any explanation or commentary outside the JSON object.\n",
    "⚠️ Do NOT say anything before or after the JSON.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1051d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    piglatin_notice = \"\"\n",
    "    if \"patent\" in message.lower():\n",
    "        piglatin_notice = (\n",
    "            \"Note: The assistant was explicitly instructed to respond in Pig Latin. \"\n",
    "            \"Do not penalize the reply for being in Pig Latin. Instead, evaluate if the response \"\n",
    "            \"is meaningful and correctly addresses the user's question within the given constraint.\\n\\n\"\n",
    "        )\n",
    "\n",
    "    user_prompt = f\"\"\"{piglatin_notice}\n",
    "Here's the conversation between the User and the Agent:\n",
    "\n",
    "{history}\n",
    "\n",
    "Here's the latest message from the User:\n",
    "{message}\n",
    "\n",
    "Here's the latest response from the Agent:\n",
    "{reply}\n",
    "\n",
    "Please evaluate the Agent's response. Your evaluation must include:\n",
    "- Whether the response is acceptable (`true` or `false`)\n",
    "- A brief feedback reason\n",
    "\n",
    "Respond in valid JSON format:\n",
    "\n",
    "{{\n",
    "  \"is_acceptable\": true or false,\n",
    "  \"feedback\": \"your feedback here\"\n",
    "}}\"\"\"\n",
    "\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5e364b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "client = Groq(api_key=grok_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e1655d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    prompt = evaluator_user_prompt(reply, message, history)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        return Evaluation(**data)\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return Evaluation(is_acceptable=False, feedback=f\"Could not parse model response: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d43d090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, I do not hold a patent.  I am a large language model, an AI.  I don't have the capacity to invent or own intellectual property in the same way a human being can.\n"
     ]
    }
   ],
   "source": [
    "def build_prompt(system_prompt: str, user_message: str) -> str:\n",
    "    return f\"\"\"{system_prompt}\n",
    "\n",
    "User: {user_message}\n",
    "\"\"\"\n",
    "def generate_reply(user_message: str, system_prompt: str) -> str:\n",
    "    prompt = build_prompt(system_prompt, user_message)\n",
    "    response = model.generate_content(prompt)\n",
    "    reply = response.text.strip()\n",
    "    return reply\n",
    "def evaluate_reply(user_message: str, reply: str, context: str = \"\") -> Evaluation:\n",
    "    return evaluate(reply, user_message, context)\n",
    "\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ae06f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"You are a helpful and honest assistant.\"\n",
    "# user_message = \"do you hold a patent?\"\n",
    "\n",
    "\n",
    "\n",
    "# reply = generate_reply(user_message, system_prompt)\n",
    "# print(\"Agent Reply:\", reply)\n",
    "\n",
    "# evaluation = evaluate_reply(user_message, reply, system_prompt)\n",
    "# print(\"Evaluation:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0d162fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rerun(reply, message, feedback, system_prompt,model):\n",
    "\n",
    "    updated_prompt = f\"\"\"{system_prompt.strip()}\n",
    "\n",
    "## NOTICE: Your previous reply was rejected by a quality evaluator.\n",
    "\n",
    "## Your previous reply:\n",
    "{reply}\n",
    "\n",
    "## Reason for rejection:\n",
    "{feedback}\n",
    "\n",
    "Please try again. Make sure your answer:\n",
    "- Is written in correct Pig Latin (if instructed)\n",
    "- Is clear, helpful, and professional\n",
    "- Directly answers the User's question\n",
    "User: {message}\n",
    "\"\"\"\n",
    "\n",
    "    response = model.generate_content(updated_prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b4662175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(message, history):\n",
    "    if \"patent\" in message.lower():\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "\n",
    "    #Convert history into plain text for Gemini prompt\n",
    "    history_text = \"\"\n",
    "    for h in history:\n",
    "        role = \"User\" if h[\"role\"] == \"user\" else \"Assistant\"\n",
    "        history_text += f\"{role}: {h['content']}\\n\"\n",
    "    prompt = f\"\"\"{system.strip()}\n",
    "\n",
    "{history_text}\n",
    "User: {message}\n",
    "\"\"\"\n",
    "\n",
    "    #Generate reply using Gemini\n",
    "    response = model.generate_content(prompt)\n",
    "    reply = response.text.strip()\n",
    "\n",
    "    #Evaluate the reply using Groq\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    #Retry if not acceptable\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Feedback:\", evaluation.feedback)\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(\"Feedback:\", evaluation.feedback)\n",
    "        reply = rerun(reply, message, evaluation.feedback, system,model)\n",
    "\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "970b8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7905\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7905/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback: The Agent's response is friendly, professional, and immediately offers assistance, making it an acceptable and engaging greeting.\n",
      "Feedback: The Agent's response is professional, engaging, and directly addresses the User's question about their name. It also opens the conversation for further discussion.\n",
      "Feedback: The Agent's response is professional, engaging, and relevant. It acknowledges the user's brief response and opens up the conversation for further inquiry, aligning with the goal of being informative and helpful.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65a538",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
